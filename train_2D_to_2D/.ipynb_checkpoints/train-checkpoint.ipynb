{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439eb8cb-a037-45e1-a282-d67bc642f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from config import FLAGS\n",
    "from models import generator_model, discriminator_model\n",
    "from data_loader import func_ge_A_data, func_ge_B_data\n",
    "from utils import cal_loss, how_real\n",
    "\n",
    "def main():\n",
    "    A2B_gener = generator_model()\n",
    "    B_dis = discriminator_model()\n",
    "    generator_optimizer = tf.keras.optimizers.Adam(FLAGS.lr, beta_1=0.5)\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(FLAGS.lr, beta_1=0.5)\n",
    "    \n",
    "    if FLAGS.pre_checkpoint:\n",
    "        ckpt = tf.train.Checkpoint(A2B_gener=A2B_gener, B_dis=B_dis,\n",
    "                                   generator_optimizer=generator_optimizer,\n",
    "                                   discriminator_optimizer=discriminator_optimizer)\n",
    "        ckpt_manager = tf.train.CheckpointManager(ckpt, FLAGS.pre_checkpoint_path, 5)\n",
    "        if ckpt_manager.latest_checkpoint:\n",
    "            ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "            print(\"Checkpoint restored!\")\n",
    "\n",
    "    train_data = os.listdir(FLAGS.img_path)\n",
    "    train_data = [os.path.join(FLAGS.img_path, data) for data in train_data]\n",
    "\n",
    "    total_folder = os.path.join(FLAGS.save_path, f'Date_{datetime.today().strftime(\"%m%d\")}')\n",
    "    os.makedirs(total_folder, exist_ok=True)\n",
    "\n",
    "    count = 0\n",
    "    for epoch in range(FLAGS.epochs):\n",
    "        shuffle(train_data)\n",
    "        train_data = np.array(train_data)\n",
    "\n",
    "        tr_idx = len(train_data) // FLAGS.batch_size\n",
    "        for step in range(tr_idx):\n",
    "            batch_images = train_data[step * FLAGS.batch_size:(step + 1) * FLAGS.batch_size]\n",
    "\n",
    "            B_batch_images_buf = [func_ge_B_data(batch_images[i]) / 1.5 - 1. for i in range(FLAGS.batch_size)]\n",
    "            A_batch_images_buf = [func_ge_A_data(B_batch_images_buf[i]) for i in range(FLAGS.batch_size)]\n",
    "\n",
    "            B_batch_images_buf = np.expand_dims(np.array(B_batch_images_buf), -1)\n",
    "            A_batch_images_buf = np.expand_dims(np.array(A_batch_images_buf), -1)\n",
    "\n",
    "            G_loss, D_loss = cal_loss(A_batch_images_buf, B_batch_images_buf,\n",
    "                                      A2B_gener, B_dis, generator_optimizer, discriminator_optimizer)\n",
    "\n",
    "            if count % 20 == 0:\n",
    "                print(f\"Epochs: {epoch + 1} [{step}/{tr_idx}] G_loss = {G_loss:.3f}, D_loss = {D_loss:.3f}\")\n",
    "\n",
    "            if count % int(tr_idx / FLAGS.save_num) == 0:\n",
    "                fake_B = A2B_gener(A_batch_images_buf, training=False)\n",
    "                fake_img = (fake_B[:2] + 1) * 1.5\n",
    "                fake_img = tf.squeeze(fake_img, -1)\n",
    "                fake_img = np.round(fake_img)\n",
    "                \n",
    "                real_img = (B_batch_images_buf[:2] + 1) * 1.5\n",
    "                real_img = tf.squeeze(real_img, -1)\n",
    "\n",
    "                epoch_folder = os.path.join(total_folder, f'epoch_{epoch + 1}-{1 + int((count % tr_idx) // int(tr_idx / FLAGS.save_num))}')\n",
    "                os.makedirs(epoch_folder, exist_ok=True)\n",
    "                print(f\"Make {epoch + 1}-{1 + int((count % tr_idx) // int(tr_idx / FLAGS.save_num))} folder to save samples\")\n",
    "\n",
    "                np.savetxt(os.path.join(epoch_folder, \"fake-1.txt\"), fake_img[0], fmt='%d', delimiter=',')\n",
    "                np.savetxt(os.path.join(epoch_folder, \"fake-2.txt\"), fake_img[1], fmt='%d', delimiter=',')\n",
    "                np.savetxt(os.path.join(epoch_folder, \"real-1.txt\"), real_img[0], fmt='%d', delimiter=',')\n",
    "                np.savetxt(os.path.join(epoch_folder, \"real-2.txt\"), real_img[1], fmt='%d', delimiter=',')\n",
    "\n",
    "                how_real(real_img, fake_img)\n",
    "                        \n",
    "                ckpt = tf.train.Checkpoint(A2B_gener=A2B_gener, B_dis=B_dis,\n",
    "                                           generator_optimizer=generator_optimizer,\n",
    "                                           discriminator_optimizer=discriminator_optimizer)\n",
    "                ckpt.save(os.path.join(epoch_folder, f\"GAN_{epoch}.ckpt\"))\n",
    "\n",
    "            count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
